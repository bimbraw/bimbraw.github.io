---
title: "Leveraging Ultrasound Sensing for Virtual Object Manipulation in Immersive Environments "
collection: publications
permalink: /publication/2023-12-01-bsn-2023
excerpt: 'Hand gesture recognition is a fundamental component of intuitive and immersive user interfaces in virtual reality (VR) applications. This paper presents a data-driven approach utilizing ultrasound data and deep learning techniques for hand gesture recognition in VR interfaces. The proposed methodology involves acquiring data from a subject, training a model using the acquired data, and evaluating the model performance on both the training data and during real time inference. The evaluation metrics primarily focus on accuracy percentage measuring the classifier performance in correctly classifying hand gestures. 4 hand gestures were primarily considered for the study and demonstration. For offline evaluation with a 20% test-train split, an accuracy percentage of 91% was observed. For online evaluation, an accuracy percentage of 92% was achieved. Results on the classification of 7 hand gestures were also analyzed for both online and online evaluation due to the promising results from the 4 gesture classification. The latency of the pipeline from ultrasound data acquisition using screenshots to sending commands for VR object manipulation was measured to be 59.48 milliseconds. The results demonstrate the effectiveness of the approach in accurately recognizing hand gestures, both during training and in real-time inference. We supplement our results with a video of the forearm ultrasound data being used to control a custom-designed VR game in a low-latency fashion. This research provides valuable insights into the performance and applicability of ultrasound-based hand gesture recognition techniques in VR interfaces. By employing deep learning and leveraging real-time data acquisition, this approach paves the way for intuitive and immersive interactions in various VR applications. The study contributes to the field of body sensor networks, highlighting the potential of forearm ultrasound based data-driven techniques for enhancing user interaction and immersion in VR environments. '
date: 2023-12-01
venue: 'IEEE BSN '
paperurl: 'https://ieeexplore.ieee.org/document/10331075'
citation: 'K. Bimbraw, J. Rothenberg and H. Zhang (2023). &quot;Leveraging Ultrasound Sensing for Virtual Object Manipulation in Immersive Environments&quot;, <i>IEEE 19th International Conference on Body Sensor Networks (BSN)</i>, Boston, MA, USA, 2023, pp. 1-4, doi: 10.1109/BSN58485.2023.10331075.'
---

<a href='https://ieeexplore.ieee.org/document/10331075'>Download paper here</a>


Hand gesture recognition is a fundamental component of intuitive and immersive user interfaces in virtual reality (VR) applications. This paper presents a data-driven approach utilizing ultrasound data and deep learning techniques for hand gesture recognition in VR interfaces. The proposed methodology involves acquiring data from a subject, training a model using the acquired data, and evaluating the model performance on both the training data and during real time inference. The evaluation metrics primarily focus on accuracy percentage measuring the classifier performance in correctly classifying hand gestures. 4 hand gestures were primarily considered for the study and demonstration. For offline evaluation with a 20% test-train split, an accuracy percentage of 91% was observed. For online evaluation, an accuracy percentage of 92% was achieved. Results on the classification of 7 hand gestures were also analyzed for both online and online evaluation due to the promising results from the 4 gesture classification. The latency of the pipeline from ultrasound data acquisition using screenshots to sending commands for VR object manipulation was measured to be 59.48 milliseconds. The results demonstrate the effectiveness of the approach in accurately recognizing hand gestures, both during training and in real-time inference. We supplement our results with a video of the forearm ultrasound data being used to control a custom-designed VR game in a low-latency fashion. This research provides valuable insights into the performance and applicability of ultrasound-based hand gesture recognition techniques in VR interfaces. By employing deep learning and leveraging real-time data acquisition, this approach paves the way for intuitive and immersive interactions in various VR applications. The study contributes to the field of body sensor networks, highlighting the potential of forearm ultrasound based data-driven techniques for enhancing user interaction and immersion in VR environments. 

Recommended citation: K. Bimbraw, J. Rothenberg and H. Zhang (2023). "Leveraging Ultrasound Sensing for Virtual Object Manipulation in Immersive Environments", <i>IEEE 19th International Conference on Body Sensor Networks (BSN)</i>, Boston, MA, USA, 2023, pp. 1-4, doi: 10.1109/BSN58485.2023.10331075.